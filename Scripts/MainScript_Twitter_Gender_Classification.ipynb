{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main script of gender classification on Twitter\n",
    "### The main script can be run in one go, but all the chunks that also have their own script, have a header here. So as not to lose track of the process\n",
    "### Note: All csv files can be found in the 'Data' folder for all intermediate results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Script 1. Cleaning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating two lists containing male and female tweets, plus two counts to be able to split them in a 70/20/10 division.\n",
    "\n",
    "import csv\n",
    "with open(\"gender-classifier-DFE-791531.csv\", \"r\", encoding='utf8', errors='ignore') as csvfile:\n",
    "    tweet_reader = csv.DictReader(csvfile, delimiter=',', quotechar='\"')\n",
    "    tweet_dicts = [dict(d) for d in tweet_reader]\n",
    "\n",
    "male_tweets_count = 0\n",
    "female_tweets_count = 0\n",
    "\n",
    "male_tweet_dicts = []\n",
    "female_tweet_dicts = []\n",
    "\n",
    "for item in tweet_dicts:\n",
    "    if item['gender'] == 'male':\n",
    "        male_tweets_count += 1\n",
    "        male_tweet_dicts.append(item)\n",
    "    if item['gender'] == 'female':\n",
    "        female_tweets_count += 1\n",
    "        female_tweet_dicts.append(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Script 2. Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a training, validation and test set.        \n",
    "\n",
    "training_list_male = male_tweet_dicts[0:4335]\n",
    "training_list_female = female_tweet_dicts[0:4690]\n",
    "training_list = training_list_male + training_list_female\n",
    "\n",
    "validation_list_male = male_tweet_dicts[4336:4955]\n",
    "validation_list_female = female_tweet_dicts[4690:5360]\n",
    "validation_list = validation_list_male + validation_list_female\n",
    "\n",
    "test_list_male = male_tweet_dicts[4956:6194]\n",
    "test_list_female = female_tweet_dicts[5361:6700]\n",
    "test_list = test_list_male + test_list_female"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Script 3. Dowloading all relevant packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/lisamarkslag/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "import nltk\n",
    "nltk.downloader.download('vader_lexicon')\n",
    "from spacy.tokens import Doc\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "sentiment_analyzer = SentimentIntensityAnalyzer()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Script 4. Processing the data - selecting all the relevant information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a list of dictionaries, only with the relevant information (for training).\n",
    "\n",
    "updated_training_list = []\n",
    "updated_validation_list = []\n",
    "updated_test_list = []\n",
    "\n",
    "for dictionary in training_list:\n",
    "    dict_tweets = {}\n",
    "    for column_name, value in dictionary.items():\n",
    "        if column_name in ['gender', 'text', 'retweet_count', 'created']:\n",
    "            dict_tweets[column_name] = value\n",
    "    updated_training_list.append(dict_tweets)\n",
    "    \n",
    "for dictionary in validation_list:\n",
    "    validation_tweet_dicts = {}\n",
    "    for column_name, value in dictionary.items():\n",
    "        if column_name in ['gender', 'text', 'retweet_count', 'created']:\n",
    "            validation_tweet_dicts[column_name] = value\n",
    "    updated_validation_list.append(validation_tweet_dicts)\n",
    "    \n",
    "for dictionary in test_list:\n",
    "    test_tweet_dicts = {}\n",
    "    for column_name, value in dictionary.items():\n",
    "        if column_name in ['gender', 'text', 'retweet_count', 'created']:\n",
    "            test_tweet_dicts[column_name] = value\n",
    "    updated_test_list.append(test_tweet_dicts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Script 5. Saving all the datasets (training, validation and test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving training set as csv\n",
    "training_set = \"training_set.csv\"\n",
    "with open(training_set, \"w\") as outfile_training:\n",
    "    fieldnames = ['gender', 'created', 'retweet_count', 'text']\n",
    "    writer = csv.DictWriter(outfile_training, fieldnames = fieldnames)\n",
    "    writer.writeheader()\n",
    "    for dictionary in updated_training_list:\n",
    "        writer.writerow({'gender': dictionary['gender'], 'created': dictionary['created'], 'retweet_count': dictionary['retweet_count'], 'text': dictionary['text']})\n",
    "\n",
    "#saving validation set as csv\n",
    "validation_set = \"validation_set.csv\"\n",
    "with open(validation_set, \"w\") as outfile_validation:\n",
    "    fieldnames = ['gender', 'created', 'retweet_count', 'text']\n",
    "    writer = csv.DictWriter(outfile_validation, fieldnames = fieldnames)\n",
    "    writer.writeheader()\n",
    "    for dictionary in updated_validation_list:\n",
    "        writer.writerow({'gender': dictionary['gender'], 'created': dictionary['created'], 'retweet_count': dictionary['retweet_count'], 'text': dictionary['text']})\n",
    "\n",
    "#saving test set as csv\n",
    "test_set = \"test_set.csv\"\n",
    "with open(test_set, \"w\") as outfile_test:\n",
    "    fieldnames = ['gender', 'created', 'retweet_count', 'text']\n",
    "    writer = csv.DictWriter(outfile_test, fieldnames = fieldnames)\n",
    "    writer.writeheader()\n",
    "    for dictionary in updated_test_list:\n",
    "        writer.writerow({'gender': dictionary['gender'], 'created': dictionary['created'], 'retweet_count': dictionary['retweet_count'], 'text': dictionary['text']})\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Script 6. All the functions to calculate features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining functions to call while storing the data as a csv\n",
    "\n",
    "#Punctuation and Numbers\n",
    "\n",
    "def num_comma(text_tweet):\n",
    "    \"\"\"Counting the number of comma's in a tweet\"\"\"\n",
    "    num_comma = text_tweet.count(',')\n",
    "    return(num_comma)\n",
    "\n",
    "def num_period(text_tweet):\n",
    "    \"\"\"Counting the number of periods in a tweet\"\"\"\n",
    "    num_period = text_tweet.count('.')\n",
    "    return(num_period)\n",
    "\n",
    "def num_question_mark(text_tweet):\n",
    "    \"\"\"Counting the number of question marks in a tweet\"\"\"\n",
    "    num_question_mark = text_tweet.count('?')\n",
    "    return(num_question_mark)\n",
    "\n",
    "def num_lowercase(text_tweet):\n",
    "    \"\"\"Counting the number of lowercase letters in a tweet\"\"\"\n",
    "    num_lowercase = sum(1 for c in text_tweet if c.islower())\n",
    "    return(num_lowercase)\n",
    "\n",
    "def num_uppercase(text_tweet):\n",
    "    \"\"\"Counting the number of uppercase letters in a tweet\"\"\"\n",
    "    num_uppercase = sum(1 for c in text_tweet if c.isupper())\n",
    "    return(num_uppercase)\n",
    "\n",
    "def num_numeric(text_tweet):\n",
    "    \"\"\"Counting the number of numeric characters in a tweet\"\"\"\n",
    "    num_numeric = sum(1 for c in text_tweet if c.isnumeric())\n",
    "    return(num_numeric)\n",
    "\n",
    "def count_symbols(text_tweet):\n",
    "    \"\"\"Counting the amount of symbols in a tweet\"\"\"\n",
    "    import string\n",
    "    import collections as ct\n",
    "    special_chars = string.punctuation\n",
    "    num_symbols = sum(v for k, v in ct.Counter(text_tweet).items() if k in special_chars)\n",
    "    return(num_symbols)\n",
    "\n",
    "def count_exl_marks(text_tweet):\n",
    "    \"\"\"Counting exclamation marks in a tweet\"\"\"\n",
    "    count_exl_mark = text_tweet.count(\"!\")\n",
    "    return(count_exl_mark)\n",
    "\n",
    "#Extra-linguistic features\n",
    "\n",
    "def count_reply_tweet(text_tweet):\n",
    "    \"\"\"Counting the amount of times an author replies to someone using '@'\"\"\"\n",
    "    count_reply = text_tweet.count('@')\n",
    "    return(count_reply)\n",
    "\n",
    "def contains_links(text_tweet):\n",
    "    \"\"\"Determining if a tweet contains a link\"\"\"\n",
    "    if \"https:\" in text_tweet:\n",
    "        contains_link = 1\n",
    "    if \"https:\" not in text_tweet:\n",
    "        contains_link = 0\n",
    "    return(contains_link)\n",
    "\n",
    "def contains_smiley(text_tweet):\n",
    "    \"\"\"Determining if a tweet contains a happy smiley\"\"\"\n",
    "    if \" :) \" in text_tweet:\n",
    "        contains_smiley = 1\n",
    "    if \" :) \" not in text_tweet:\n",
    "        contains_smiley = 0\n",
    "    return(contains_smiley)\n",
    "\n",
    "def num_hashtags(text_tweet):\n",
    "    \"\"\"Counting the number of hashtags in a tweet\"\"\"\n",
    "    num_hashtags = text_tweet.count('#')\n",
    "    return(num_hashtags)\n",
    "\n",
    "#Linguistic\n",
    "\n",
    "def count_number_verbs(text_tweet):\n",
    "    \"\"\"Counting the number of verbs in a tweet\"\"\"\n",
    "    doc = nlp(text_tweet)\n",
    "    pos_tags = []\n",
    "    for token in doc: \n",
    "        pos_tag = token.pos_\n",
    "        pos_tags.append(pos_tag)\n",
    "    count_verbs = pos_tags.count(\"VERB\")\n",
    "    return(count_verbs)\n",
    "\n",
    "def count_number_nouns(text_tweet):\n",
    "    \"\"\"Counting the number of nouns in a tweet\"\"\"\n",
    "    doc = nlp(text_tweet)\n",
    "    pos_tags = []\n",
    "    for token in doc: \n",
    "        pos_tag = token.pos_\n",
    "        pos_tags.append(pos_tag)\n",
    "    count_nouns = pos_tags.count(\"NOUN\")\n",
    "    return(count_nouns)\n",
    "\n",
    "def count_tokens(text_tweet):\n",
    "    \"\"\"Counting the amount of tokens (words) in a tweet\"\"\"\n",
    "    doc = nlp(text_tweet)\n",
    "    num_tokens = len(doc)\n",
    "    return(num_tokens)\n",
    "\n",
    "def num_like(text_tweet):\n",
    "    \"\"\"Counting the amount of times the author uses the word 'like'\"\"\"\n",
    "    number_likes = text_tweet.count(\" like \") + text_tweet.count(\" Like \") + text_tweet.count(\"Like \")\n",
    "    return(number_likes)\n",
    "\n",
    "def num_first_person(text_tweet):\n",
    "    \"\"\"Counting the number of first person singular expressions\"\"\"\n",
    "    num_I = text_tweet.count(\"I \") + text_tweet.count(\" I \") + text_tweet.count(\" i \")\n",
    "    num_my = text_tweet.count(\"My \") + text_tweet.count(\" My \") + text_tweet.count(\" my \") + text_tweet.count(\"my \")\n",
    "    num_Im = text_tweet.count(\" I'm \") + text_tweet.count(\"I'm \") + text_tweet.count(\" Im \") + text_tweet.count(\" i'm \") + text_tweet.count(\" im \")\n",
    "    num_Ihave = text_tweet.count(\" I have \") + text_tweet.count(\"I have \") + text_tweet.count(\" I Have \") + text_tweet.count(\"I Have \")\n",
    "    num_me = text_tweet.count(\" me \") + text_tweet.count(\" Me \") + text_tweet.count(\"Me \")\n",
    "    num_Iam = text_tweet.count(\" I am \") + text_tweet.count(\"I am \")\n",
    "    num_first_person = num_I + num_my + num_Im + num_Ihave + num_me + num_Iam\n",
    "    return(num_first_person)\n",
    "\n",
    "#Sentiment\n",
    "\n",
    "def positive_scores(text_tweet):\n",
    "    \"\"\"Measuring the positive sentiment of a text in a tweet\"\"\"\n",
    "    doc=nlp(text_tweet)\n",
    "    doc.set_extension('polarity_scores', getter=polarity_scores, force=True)\n",
    "    polarity_score = doc._.polarity_scores\n",
    "    polarity_scores(doc)\n",
    "    return(polarity_score[\"pos\"])\n",
    "\n",
    "\n",
    "def negative_scores(text_tweet):\n",
    "    \"\"\"Measuring the negative sentiment of a text in a tweet\"\"\"\n",
    "    doc=nlp(text_tweet)\n",
    "    doc.set_extension('polarity_scores', getter=polarity_scores, force=True)\n",
    "    polarity_score = doc._.polarity_scores\n",
    "    polarity_scores(doc)\n",
    "    return(polarity_score[\"neg\"])\n",
    "\n",
    "def neutral_scores(text_tweet):\n",
    "    \"\"\"Measuring the neutral sentiment of a text in a tweet\"\"\"\n",
    "    doc=nlp(text_tweet)\n",
    "    doc.set_extension('polarity_scores', getter=polarity_scores, force=True)\n",
    "    polarity_score = doc._.polarity_scores\n",
    "    polarity_scores(doc)\n",
    "    return(polarity_score[\"neu\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Script 7. Storing and opening the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Storing the training data as csv\n",
    "\n",
    "outfilename = \"training_set_features.csv\"\n",
    "with open(outfilename, \"w\") as outfile:\n",
    "    fieldnames = ['gender', 'created', 'retweet_count', 'text', 'num_exclamation', 'num_tokens', 'num_replys', 'contains_link', 'num_verbs', 'num_nouns', 'neg_score', 'pos_score', 'neu_score', 'num_commas', 'num_period', 'num_question_mark', 'num_upper', 'num_lower', 'num_num', 'contains_smiley', 'num_likes', 'num_first_person', 'num_hashtags', 'num_symbols']\n",
    "    writer = csv.DictWriter(outfile, fieldnames = fieldnames)\n",
    "    writer.writeheader()\n",
    "    for dictionary in updated_training_list:\n",
    "        exl_count = count_exl_marks(dictionary[\"text\"])\n",
    "        token_count = count_tokens(dictionary[\"text\"])\n",
    "        reply_count = count_reply_tweet(dictionary[\"text\"])\n",
    "        link_container = contains_links(dictionary[\"text\"])\n",
    "        verb_count = count_number_verbs(dictionary[\"text\"])\n",
    "        noun_count = count_number_nouns(dictionary[\"text\"])\n",
    "        neg_score = negative_scores(dictionary[\"text\"])\n",
    "        pos_score = positive_scores(dictionary[\"text\"])\n",
    "        neu_score = neutral_scores(dictionary[\"text\"])\n",
    "        comma_count = num_comma(dictionary[\"text\"])\n",
    "        period_count = num_period(dictionary[\"text\"])\n",
    "        question_count = num_question_mark(dictionary[\"text\"])\n",
    "        uppercase_count = num_uppercase(dictionary[\"text\"])\n",
    "        lowercase_count = num_lowercase(dictionary[\"text\"])\n",
    "        num_count = num_numeric(dictionary[\"text\"])\n",
    "        smiley_container = contains_smiley(dictionary[\"text\"])\n",
    "        like_count = num_like(dictionary[\"text\"])\n",
    "        first_person_count = num_first_person(dictionary[\"text\"])\n",
    "        hashtag_count = num_hashtags(dictionary[\"text\"])\n",
    "        symbol_count = count_symbols(dictionary[\"text\"])\n",
    "        writer.writerow({'gender': dictionary['gender'], 'created': dictionary['created'], 'retweet_count': dictionary['retweet_count'], 'text': dictionary[\"text\"], 'num_exclamation': exl_count, 'num_tokens': token_count, 'num_replys': reply_count, 'contains_link': link_container, 'num_verbs': verb_count, 'num_nouns': noun_count, 'neg_score': neg_score, 'pos_score': pos_score, 'neu_score': neu_score, 'num_commas': comma_count, 'num_period': period_count, 'num_question_mark': question_count, 'num_upper': uppercase_count, 'num_num': num_count, 'contains_smiley': smiley_container, 'num_likes': like_count, 'num_first_person': first_person_count, 'num_hashtags': hashtag_count, 'num_lower': lowercase_count, 'num_symbols': symbol_count})\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../../../../../Desktop/training_set_features.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-a86b74c612e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Opening the training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../../../../../../Desktop/training_set_features.csv\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcsvfile2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mtweet_reader_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDictReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsvfile2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquotechar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\"'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtweet_dicts_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtweet_reader_2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../../../../../Desktop/training_set_features.csv'"
     ]
    }
   ],
   "source": [
    "#Opening the training data\n",
    "        \n",
    "with open(\"training_set_features.csv\") as csvfile2:\n",
    "    tweet_reader_2 = csv.DictReader(csvfile2, delimiter=',', quotechar='\"')\n",
    "    tweet_dicts_2 = [dict(d) for d in tweet_reader_2]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Script 8. Building the classifier without specified weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier(tweet):\n",
    "    ft1 = count_reply_tweet(tweet[\"text\"])\n",
    "    ft2 = contains_links(tweet[\"text\"])\n",
    "    ft3 = contains_smiley(tweet[\"text\"])\n",
    "    ft4 = num_hashtags(tweet[\"text\"])\n",
    "    ft5 = count_number_nouns(tweet[\"text\"])\n",
    "    ft6 = count_number_verbs(tweet[\"text\"])\n",
    "    ft7 = count_tokens(tweet[\"text\"])\n",
    "    ft8 = num_like(tweet[\"text\"])\n",
    "    ft9 = num_first_person(tweet[\"text\"])\n",
    "    ft10 = num_lowercase(tweet[\"text\"])\n",
    "    ft11 = num_uppercase(tweet[\"text\"])\n",
    "    ft12 = positive_scores(tweet[\"text\"])\n",
    "    ft13 = negative_scores(tweet[\"text\"])\n",
    "    ft14 = neutral_scores(tweet[\"text\"])\n",
    "    ft15 = num_comma(tweet[\"text\"])\n",
    "    ft16 = num_period(tweet[\"text\"])\n",
    "    ft17 = num_question_mark(tweet[\"text\"])\n",
    "    ft18 = count_exl_marks(tweet[\"text\"])\n",
    "    ft19 = num_numeric(tweet[\"text\"])\n",
    "    ft20 = count_symbols(tweet[\"text\"])\n",
    "    distance_fm1 = abs(fm1 - ft1)\n",
    "    distance_ff1 = abs(ff1 - ft1) \n",
    "    distance_fm2 = abs(fm2 - ft2)\n",
    "    distance_ff2 = abs(ff2 - ft2)\n",
    "    distance_fm3 = abs(fm3 - ft3)\n",
    "    distance_ff3 = abs(ff3 - ft3)\n",
    "    distance_fm4 = abs(fm4 - ft4)\n",
    "    distance_ff4 = abs(ff4 - ft4) \n",
    "    distance_fm5 = abs(fm5 - ft5)\n",
    "    distance_ff5 = abs(ff5 - ft5) \n",
    "    distance_fm6 = abs(fm6 - ft6)\n",
    "    distance_ff6 = abs(ff6 - ft6) \n",
    "    distance_fm7 = abs(fm7 - ft7)\n",
    "    distance_ff7 = abs(ff7 - ft7) \n",
    "    distance_fm8 = abs(fm8 - ft8)\n",
    "    distance_ff8 = abs(ff8 - ft8)\n",
    "    distance_fm9 = abs(fm9 - ft9)\n",
    "    distance_ff9 = abs(ff9 - ft9)\n",
    "    distance_fm10 = abs(fm10 - ft10)\n",
    "    distance_ff10 = abs(ff10 - ft10)\n",
    "    distance_fm11 = abs(fm11 - ft11)\n",
    "    distance_ff11 = abs(ff11 - ft11)\n",
    "    distance_fm12 = abs(fm12 - ft12)\n",
    "    distance_ff12 = abs(ff12 - ft12)\n",
    "    distance_fm13 = abs(fm13 - ft13)\n",
    "    distance_ff13 = abs(ff13 - ft13)\n",
    "    distance_fm14 = abs(fm14 - ft14)\n",
    "    distance_ff14 = abs(ff14 - ft14)\n",
    "    distance_fm15 = abs(fm15 - ft15)\n",
    "    distance_ff15 = abs(ff15 - ft15)\n",
    "    distance_fm16 = abs(fm16 - ft16)\n",
    "    distance_ff16 = abs(ff16 - ft16)\n",
    "    distance_fm17 = abs(fm17 - ft17)\n",
    "    distance_ff17 = abs(ff17 - ft17)\n",
    "    distance_fm18 = abs(fm18 - ft18)\n",
    "    distance_ff18 = abs(ff18 - ft18)\n",
    "    distance_fm19 = abs(fm19 - ft19)\n",
    "    distance_ff19 = abs(ff19 - ft19)\n",
    "    distance_fm20 = abs(fm20 - ft20)\n",
    "    distance_ff20 = abs(ff20 - ft20)\n",
    "    \n",
    "    total_distance_m = distance_fm1 + distance_fm2 + distance_fm3 + distance_fm4 + distance_fm5 + distance_fm6 + distance_fm7 + distance_fm8 + distance_fm9 + distance_fm10 + distance_fm11 + distance_fm12 + distance_fm13 + distance_fm14 + distance_fm15 + distance_fm16 + distance_fm17 + distance_fm18 + distance_fm19 + distance_fm20 \n",
    "    total_distance_f = distance_ff1 + distance_ff2 + distance_ff3 + distance_ff4 + distance_ff5 + distance_ff6 + distance_ff7 + distance_ff8 + distance_ff9 + distance_ff10 + distance_ff11 + distance_ff12 + distance_ff13 + distance_ff14 + distance_ff15 + distance_ff16 + distance_ff17 + distance_ff18 + distance_ff19 + distance_ff20\n",
    "    \n",
    "    if total_distance_m > total_distance_f:\n",
    "        prediction = \"female\"\n",
    "    if total_distance_f > total_distance_m:\n",
    "        prediction = \"male\"\n",
    "    \n",
    "    return(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Script 9. Building the classifier with specified weights and including only relevant features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifierweights(tweet):\n",
    "    ft2 = contains_links(tweet[\"text\"])\n",
    "    ft4 = num_hashtags(tweet[\"text\"])\n",
    "    ft5 = count_number_nouns(tweet[\"text\"])\n",
    "    ft6 = count_number_verbs(tweet[\"text\"])\n",
    "    ft7 = count_tokens(tweet[\"text\"])\n",
    "    ft9 = num_first_person(tweet[\"text\"])\n",
    "    ft11 = num_uppercase(tweet[\"text\"])\n",
    "    ft12 = positive_scores(tweet[\"text\"])\n",
    "    ft15 = num_comma(tweet[\"text\"])\n",
    "    ft16 = num_period(tweet[\"text\"])\n",
    "    ft17 = num_question_mark(tweet[\"text\"])\n",
    "    ft18 = count_exl_marks(tweet[\"text\"])\n",
    "    ft19 = num_numeric(tweet[\"text\"])\n",
    "    distance_fm2 = abs(fm2 - ft2)\n",
    "    distance_ff2 = abs(ff2 - ft2)\n",
    "    distance_fm4 = abs(fm4 - ft4)\n",
    "    distance_ff4 = abs(ff4 - ft4) \n",
    "    distance_fm5 = abs(fm5 - ft5)\n",
    "    distance_ff5 = abs(ff5 - ft5) \n",
    "    distance_fm6 = abs(fm6 - ft6)\n",
    "    distance_ff6 = abs(ff6 - ft6) \n",
    "    distance_fm7 = abs(fm7 - ft7)\n",
    "    distance_ff7 = abs(ff7 - ft7) \n",
    "    distance_fm9 = abs(fm9 - ft9)\n",
    "    distance_ff9 = abs(ff9 - ft9)\n",
    "    distance_fm11 = abs(fm11 - ft11)\n",
    "    distance_ff11 = abs(ff11 - ft11)\n",
    "    distance_fm12 = abs(fm12 - ft12)\n",
    "    distance_ff12 = abs(ff12 - ft12)\n",
    "    distance_fm15 = abs(fm15 - ft15)\n",
    "    distance_ff15 = abs(ff15 - ft15)\n",
    "    distance_fm16 = abs(fm16 - ft16)\n",
    "    distance_ff16 = abs(ff16 - ft16)\n",
    "    distance_fm17 = abs(fm17 - ft17)\n",
    "    distance_ff17 = abs(ff17 - ft17)\n",
    "    distance_fm18 = abs(fm18 - ft18)\n",
    "    distance_ff18 = abs(ff18 - ft18)\n",
    "    distance_fm19 = abs(fm19 - ft19)\n",
    "    distance_ff19 = abs(ff19 - ft19)\n",
    "    \n",
    "    total_distance_m = distance_fm2 + distance_fm4 + distance_fm5 + distance_fm6 + distance_fm7 + distance_fm9*50 + distance_fm11 + distance_fm12*10 + distance_fm15 + distance_fm16 + distance_fm17 + distance_fm18 + distance_fm19 \n",
    "    total_distance_f = distance_ff2 + distance_ff4 + distance_ff5 + distance_ff6 + distance_ff7 + distance_ff9*50 + distance_ff11 + distance_ff12*10 + distance_ff15 + distance_ff16 + distance_ff17 + distance_ff18 + distance_ff19\n",
    "    \n",
    "    if total_distance_m > total_distance_f:\n",
    "        prediction = \"female\"\n",
    "    if total_distance_f > total_distance_m:\n",
    "        prediction = \"male\"\n",
    "    \n",
    "    return(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Script 10. CSV-files for validation -and test set (first without specified weights, second with specified weights and relevant features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating csv files for calculating the accuracy (using classifier without weights and all features)\n",
    "\n",
    "validation_prediction_noweights = \"validation_noweights_prediction.csv\"\n",
    "with open(validation_prediction_noweights, \"w\") as validation_noweights_outfile:\n",
    "    fieldnames = ['text_tweet', 'gold', 'prediction']\n",
    "    writer = csv.DictWriter(validation_noweights_outfile, fieldnames = fieldnames)\n",
    "    writer.writeheader()\n",
    "    for dictionary in validation_list:\n",
    "        classification = classifier(dictionary)\n",
    "        writer.writerow({'text_tweet': dictionary['text'], 'gold': dictionary['gender'], 'prediction': classification})\n",
    "        \n",
    "test_prediction_noweights = \"test_noweights_prediction.csv\"\n",
    "with open(test_prediction_noweights, \"w\") as test_noweights_outfile:\n",
    "    fieldnames = ['text_tweet', 'gold', 'prediction']\n",
    "    writer = csv.DictWriter(test_noweights_outfile, fieldnames = fieldnames)\n",
    "    writer.writeheader()\n",
    "    for dictionary in test_list:\n",
    "        classification = classifier(dictionary)\n",
    "        writer.writerow({'text_tweet': dictionary['text'], 'gold': dictionary['gender'], 'prediction': classification})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating csv files for calculating the accuracy (using classifier with weights and 13 features)\n",
    "\n",
    "validation_prediction_weights = \"validation_weights_prediction.csv\"\n",
    "with open(validation_prediction_weights, \"w\") as validation_weights_outfile:\n",
    "    fieldnames = ['text_tweet', 'gold', 'prediction']\n",
    "    writer = csv.DictWriter(validation_weights_outfile, fieldnames = fieldnames)\n",
    "    writer.writeheader()\n",
    "    for dictionary in validation_list:\n",
    "        classification = classifierweights(dictionary)\n",
    "        writer.writerow({'text_tweet': dictionary['text'], 'gold': dictionary['gender'], 'prediction': classification})\n",
    "\n",
    "test_prediction_weights = \"test_weights_prediction.csv\"\n",
    "with open(test_prediction_weights, \"w\") as test_weights_outfile:\n",
    "    fieldnames = ['text_tweet', 'gold', 'prediction']\n",
    "    writer = csv.DictWriter(test_weights_outfile, fieldnames = fieldnames)\n",
    "    writer.writeheader()\n",
    "    for dictionary in test_list:\n",
    "        classification = classifierweights(dictionary)\n",
    "        writer.writerow({'text_tweet': dictionary['text'], 'gold': dictionary['gender'], 'prediction': classification})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Script 11. Calculating the accuracy of classifier (without and with specified weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../../../../../Desktop/validation_noweights_prediction.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-35eb85450640>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#opening the csvs and calculating the accuracy of the classifier while looking at different sets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../../../../../../Desktop/validation_noweights_prediction.csv\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcsvfile3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprediction_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDictReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsvfile3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquotechar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\"'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprediction_dicts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprediction_reader\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../../../../../Desktop/validation_noweights_prediction.csv'"
     ]
    }
   ],
   "source": [
    "#opening the csvs and calculating the accuracy of the classifier while looking at different sets\n",
    "\n",
    "with open(\"validation_noweights_prediction.csv\") as csvfile3:\n",
    "    prediction_reader = csv.DictReader(csvfile3, delimiter=',', quotechar='\"')\n",
    "    prediction_dicts = [dict(d) for d in prediction_reader]\n",
    "\n",
    "with open(\"test_noweights_prediction.csv\") as csvfile4:\n",
    "    prediction_reader_2 = csv.DictReader(csvfile4, delimiter=',', quotechar='\"')\n",
    "    prediction_dicts_2 = [dict(d) for d in prediction_reader_2]\n",
    "    \n",
    "with open(\"validation_weights_prediction.csv\") as csvfile5:\n",
    "    prediction_reader_3 = csv.DictReader(csvfile5, delimiter=',', quotechar='\"')\n",
    "    prediction_dicts_3 = [dict(d) for d in prediction_reader_3]\n",
    "    \n",
    "with open(\"test_weights_prediction.csv\") as csvfile6:\n",
    "    prediction_reader_4 = csv.DictReader(csvfile6, delimiter=',', quotechar='\"')\n",
    "    prediction_dicts_4 = [dict(d) for d in prediction_reader_4]\n",
    "\n",
    "def accuracy(list_of_tweets):\n",
    "    correct_count = 0\n",
    "    total_count = len(list_of_tweets)\n",
    "    for tweet in list_of_tweets:\n",
    "        if tweet['gold'] == tweet['prediction']:\n",
    "            correct_count += 1\n",
    "    accuracy = correct_count/total_count*100\n",
    "    return(accuracy)\n",
    "\n",
    "print(\"The accuracy of the classifier with all (20) features and without weights on the validation set is:\", accuracy(prediction_dicts), \"\\nThe accuracy of the classifier with all (20) features and without weights on the test set is:\", accuracy(prediction_dicts_2), \"\\nThe accuracy of the classifier with only 13 features and with weights on feature 9 and 12 on the validation set is:\", accuracy(prediction_dicts_3), \"\\nThe accuracy of the classifier with only 13 features and with weights on feature 9 and 12 on the test set is:\", accuracy(prediction_dicts_4))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
